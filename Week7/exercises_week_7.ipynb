{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hanlululu/02807-Computational-tools-for-Data-Science/blob/main/Week7/exercises_week_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlMcbNUbMqnF"
      },
      "source": [
        "# 02807 - Week 7 Exercises:  Getting started with Spark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXQzA01OS_yQ"
      },
      "source": [
        "# Setup\n",
        "\n",
        "* See also this week's slides for context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-10-11T19:21:00.219855Z",
          "start_time": "2021-10-11T19:20:59.476023Z"
        },
        "id": "32YylmidxfXV",
        "outputId": "5e380d9a-fa4e-439e-e1e5-9bb7858d0767"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspark in /Users/martinholmjensen/miniforge3/envs/py38/lib/python3.8/site-packages (3.0.0)\r\n",
            "Requirement already satisfied: py4j==0.10.9 in /Users/martinholmjensen/miniforge3/envs/py38/lib/python3.8/site-packages (from pyspark) (0.10.9)\r\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-10-11T19:21:00.223652Z",
          "start_time": "2021-10-11T19:21:00.221268Z"
        },
        "id": "dhzk3GE6S9RC"
      },
      "outputs": [],
      "source": [
        "# Instructions on p. 20 Learning Spark, 2nd ed.\n",
        "# Here's a quick-guide, googling may also be required\n",
        "# 1) Install pyspark via conda/pip\n",
        "#          pyspark requires the JAVA_HOME environment variable is set.\n",
        "# 2) Install JRE/JDK, figure out the install location\n",
        "#          You will need to install Java 8 or above\n",
        "# 3) Update the JAVA_HOME environment variable set programmatically below \n",
        "#    with your installation specifics\n",
        "\n",
        "# Some maybe helpful pointers on JRE/JDK:\n",
        "# MacOS: Consider using https://github.com/AdoptOpenJDK/homebrew-openjdk\n",
        "# Debian (colab): !apt install openjdk-8-jdk-headless -qq\n",
        "# Windows: \n",
        "#    If you didn't change the path during installation, it'll be \n",
        "#    something like C:\\Program Files\\Java\\jdk1.8.0_65\n",
        "#    You can also type where java at the command prompt.\n",
        "\n",
        "# JAVA_HOME environment variable is set programatically below\n",
        "# but you must point it to your local install\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/Library/Java/JavaVirtualMachines/adoptopenjdk-8.jdk/Contents/Home/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-10-11T19:21:00.533785Z",
          "start_time": "2021-10-11T19:21:00.224806Z"
        },
        "id": "xgQaRx6rSaf9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark import SparkContext, SparkConf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUD5XpD_SagA"
      },
      "source": [
        "Let's initialise a **Spark Session**. \n",
        "* A SparkSession object is the entry point to the Spark functionality. \n",
        "* When you create the SparkSession object, it initiates a **Spark Application** which all the code for that Session will run on.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-10-11T19:21:04.257817Z",
          "start_time": "2021-10-11T19:21:00.534459Z"
        },
        "id": "7ft3VivrSagB"
      },
      "outputs": [],
      "source": [
        "# create the Spark session\n",
        "conf = SparkConf().set(\"spark.ui.port\", \"4050\")\n",
        "sc = pyspark.SparkContext(conf=conf)\n",
        "spark = SparkSession.builder.getOrCreate()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-10-11T19:21:04.981186Z",
          "start_time": "2021-10-11T19:21:04.258838Z"
        },
        "id": "Mc8uFlalxfXZ",
        "outputId": "0cee8414-d95d-4350-fa2a-3e60b08be1ef"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://csrls2.private.imm.dtu.dk:4052\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.0.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x127d82940>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "spark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ectQxRreAvJ"
      },
      "source": [
        "# Exercise 1: The Titanic Dataset\n",
        "\n",
        "In this exercise you should use Spark to count the number of Titanic passengers in different age brackets. More specifically, you need to count the number of people age 0 to 9, 10 to 19, and so on.\n",
        "\n",
        "The data is available [here](https://courses.compute.dtu.dk/02807/2021/lectures/week7/titanic_full.csv) and should be loaded into a dataframe in the next cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-10-11T19:23:58.310858Z",
          "start_time": "2021-10-11T19:23:58.307788Z"
        },
        "id": "my6Awbl-e4AO"
      },
      "outputs": [],
      "source": [
        "# Your code goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSZvg7eOe7ok"
      },
      "source": [
        "## Cleaning the data\n",
        "\n",
        "Remove the rows that do not have an age \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-10-11T19:24:01.014994Z",
          "start_time": "2021-10-11T19:24:01.013008Z"
        },
        "id": "OJrRTjQLfTsq"
      },
      "outputs": [],
      "source": [
        "# Your code goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jzO0ggSfAFs"
      },
      "source": [
        "## Adding age brackets \n",
        "\n",
        "Create a new column with a value that identifies the bracket that passengers are in"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-10-11T19:24:05.737832Z",
          "start_time": "2021-10-11T19:24:05.735848Z"
        },
        "id": "S2bOTGcpfIES",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Your code goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCLsqtqVfKwb"
      },
      "source": [
        "## Age bracket counts\n",
        "\n",
        "Create a Spark dataframe with the sum of passengers in each bracket, and sort it by Age Bracket (youngest to oldest)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-10-11T19:24:11.572357Z",
          "start_time": "2021-10-11T19:24:11.569948Z"
        },
        "id": "wm9fldBlfVmK"
      },
      "outputs": [],
      "source": [
        "# Your code goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_Hx1zOgxfXb"
      },
      "source": [
        "## Spark plans and jobs\n",
        "\n",
        "1) Display the plans spark creates to achieve your query in the previous exercise. Identify how many shuffles/exchanges are to take place.\n",
        "\n",
        "2) How many jobs are spawned when your query is executed? (Inspect via the Spark UI)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1BUol8oxfXb"
      },
      "source": [
        "*Your answers here*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-10-11T19:24:18.049147Z",
          "start_time": "2021-10-11T19:24:18.047166Z"
        },
        "id": "YsnaNNC8xfXc"
      },
      "outputs": [],
      "source": [
        "# Your code goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvB1CeqSfYXP"
      },
      "source": [
        "# Exercise 2: Actions and transformations\n",
        "\n",
        "For each of the following Spark operations, decide if they are transformations or actions. If they are transformations, determine if they are wide or narrow.\n",
        "\n",
        "* ``select()``\n",
        "* `groupBy()`\n",
        "* `filter()`\n",
        "* `where()`\n",
        "* `count()`\n",
        "* `show()`\n",
        "* `agg()`\n",
        "* `write()`\n",
        "* `sort()`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MQ2mtJLfu5_"
      },
      "source": [
        "*Your answers here*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wztxj5t_6m-h"
      },
      "source": [
        "# Exercise 3: Exploratory data analysis for the Chicago crime dataset\n",
        "The Chicago Crime dataset contains a summary of the reported crimes occurred in the City of Chicago from 2001 to 2017. \n",
        "\n",
        "We'll work on a sample of it available [here](https://courses.compute.dtu.dk/02807/2021/lectures/week7/reported-crimes.csv).\n",
        "\n",
        "You may optionally work on the entire dataset which is available [here](https://data.cityofchicago.org/api/views/ijzp-q8t2/rows.csv?accessType=DOWNLOAD).\n",
        "\n",
        "Now load the data you've downloaded locally into a spark dataframe, and proceed to answer the questions below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-10-11T19:24:30.398620Z",
          "start_time": "2021-10-11T19:24:30.396458Z"
        },
        "id": "EfnqE8Jx_Eve"
      },
      "outputs": [],
      "source": [
        "# Your code goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DknyPxfkFFVz"
      },
      "source": [
        "## What percentage of reported crimes resulted in an arrest?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-10-11T19:24:33.404667Z",
          "start_time": "2021-10-11T19:24:33.402544Z"
        },
        "id": "d9S4hZanFPCf"
      },
      "outputs": [],
      "source": [
        "# Your code goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uToZfa01Fqi9"
      },
      "source": [
        "## What are the top 3 locations for reported crimes?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-10-11T19:24:37.437255Z",
          "start_time": "2021-10-11T19:24:37.435174Z"
        },
        "id": "B3bxfL6wFvjJ"
      },
      "outputs": [],
      "source": [
        "# Your code goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d25WmF0dxfXd"
      },
      "source": [
        "## What are the top 3 locations for reported thefts?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-10-11T19:24:39.930450Z",
          "start_time": "2021-10-11T19:24:39.928468Z"
        },
        "id": "SOwZ0tfUxfXd"
      },
      "outputs": [],
      "source": [
        "# Your code goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vI6uPOV7GCAH"
      },
      "source": [
        "## What is the most common primary type of crime in district 22?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-10-11T19:24:43.025574Z",
          "start_time": "2021-10-11T19:24:43.023609Z"
        },
        "id": "ojh8eHFUGNG9"
      },
      "outputs": [],
      "source": [
        "# Your code goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8yvm-eBxfXe"
      },
      "source": [
        "## What are the suffixes where crime is taking place?\n",
        "\n",
        "Inspect the `BLOCK` column to observe common suffixes are `AVE, BLVD, ST, DR, PL, RD` (there's a few more even). Create a dataframe that contains the frequency of each block suffix, e.g. showing there are 258 `AVE` suffixes and 191 `ST` suffixes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-10-11T19:24:45.384087Z",
          "start_time": "2021-10-11T19:24:45.381683Z"
        },
        "id": "mhdg4V8PxfXe"
      },
      "outputs": [],
      "source": [
        "# Your code goes here"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "name": "exercises_week_7.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "f1d60ef3148d6d6f99d64de6ef09e0267d4db5c62a0823eaf2b9aa582c08f8e5"
    },
    "kernelspec": {
      "display_name": "Python 3.7.6 64-bit ('base': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
